library(jsonlite)
library(dplyr)
library(jsonlite)
library(dplyr)
library(utils)
library(stringi)
library(jsonlite)
library(dplyr)
library(utils)
library(stringi)
# Adds duplicate question dataset
duplicate_questions_raw <- fromJSON("stackexchange_duplicatequestions.json")
colnames(duplicate_questions_raw) <- c("sentence1", "sentence2")
set.seed(123)
duplicate_questions <- as.data.frame(duplicate_questions_raw,
row.names = c("sentence1", "sentence2"))
# Generate random ids
duplicate_questions$id <- stri_rand_strings(nrow(duplicate_questions),
50,
pattern="[0-9a-f]")
# Set is_duplicate to 1.0
duplicate_questions <- duplicate_questions
duplicate_questions <- duplicate_questions %>%
mutate(is_duplicate = 1.0) %>%
select(id, sentence1, sentence2, is_duplicate)
# Just get the first 1000 observations
write.csv(duplicate_questions, "para-train-duplicate-questions.csv",
row.names = FALSE, sep="\t")
# Make sure that csv is tab delimited
# Add merged para
para_base <- read.delim("quora-train.csv")
para_merged <- rbind(para_base, duplicate_questions)
# Make sure that csv is tab delimited
write.table(para_merged, "para-train-merged.csv",
row.names = FALSE, sep="\t")
# Adds duplicate question dataset
duplicate_questions_raw <- fromJSON("stackexchange_duplicatequestions.json")
colnames(duplicate_questions_raw) <- c("sentence1", "sentence2")
set.seed(123)
duplicate_questions <- as.data.frame(duplicate_questions_raw,
row.names = c("sentence1", "sentence2"))
# Generate random ids
duplicate_questions$id <- stri_rand_strings(nrow(duplicate_questions),
50,
pattern="[0-9a-f]")
# Set is_duplicate to 1.0
duplicate_questions <- duplicate_questions[0:50000]
# Adds duplicate question dataset
duplicate_questions_raw <- fromJSON("stackexchange_duplicatequestions.json")
colnames(duplicate_questions_raw) <- c("sentence1", "sentence2")
set.seed(123)
duplicate_questions <- as.data.frame(duplicate_questions_raw,
row.names = c("sentence1", "sentence2"))
# Generate random ids
duplicate_questions$id <- stri_rand_strings(nrow(duplicate_questions),
50,
pattern="[0-9a-f]")
# Set is_duplicate to 1.0
duplicate_questions <- duplicate_questions[0:50000,]
duplicate_questions <- duplicate_questions %>%
mutate(is_duplicate = 1.0) %>%
select(id, sentence1, sentence2, is_duplicate)
# Just get the first 1000 observations
write.csv(duplicate_questions, "para-train-duplicate-questions.csv",
row.names = FALSE, sep="\t")
View(duplicate_questions)
# Make sure that csv is tab delimited
# Add merged para
para_base <- read.delim("quora-train.csv")
para_merged <- rbind(para_base, duplicate_questions)
# Make sure that csv is tab delimited
write.table(para_merged, "para-train-merged.csv",
row.names = FALSE, sep="\t")
View(para_base)
